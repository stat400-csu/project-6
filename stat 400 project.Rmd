---
title: "Project 6 for STAT 400"
author: "Juliette Dashe"
date: "2025-11-07"
output: html_document
---

```{r setup, include=FALSE}
# Loading in packages

knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(deSolve)
library(mvtnorm)
library(pracma)
library(reshape)
library(ggplot2)
library(tidyr)
library(ggpubr)
library(ggthemes)
library(latex2exp)

# Loading in functions created by Moffat
source('generate_data.R')
source('additional_functions.R')
```

Author's Code: ANY EDITS HAVE COMMENT WITH "JD"

```{r}
set.seed(400)
## MAKING AUTHOR'S CODE INTO A FUNCTION so I can use other values later, commenting out utility plots 
run_smc_simulation <- function(input_N = 500, input_R = 0, input_I = 15, input_seed = 400) { #JD changed I from 25 to 15 for computational purposes and made into a function
  
  # 1. SETUP PARAMETERS
  set.seed(400) 
  
  # Override standard variables with Function Arguments
  N <- input_N
  R <- input_R
  I <- input_I
  
  # Fixed Project Settings
  models <- 1:4 %>% matrix(nrow = 1)
  modeltype <- list("Beta Binomial type 2 functional response model",
                    "Beta Binomial type 3 functional response model",
                    "Binomial type 2 functional response model",
                    "Binomial type 3 functional response model")
  
  # Load example dataset for methods that require it
  if (R %in% 4:5){
    dataset <- read.table("papanikolau_data.txt", sep = " ", col.names = c("N", "n")) %>% as.matrix
  }
  
  # Select "true values" of parameters for methods that require it
  if (R %in% c(0:3,5)){
    a <- 0.5
    Th <- 0.7
    lambda <- 0.5
    parameter_set <- matrix(c(a, Th, lambda), nrow = 1) %>% log
    M_true <- 1
  }
  
  # Assign values to parameters 
  K <- length(models) # number of models
  E <- N/2 # threshold for ESS for SMC
  Nmin <- 1 # min value in the discrete design space
  Nmax <- 300 # max value in the discrete design space
  time <- 24 # length of time that predator has access to prey in hours
  tol <- 2 # tolerance for ESS 
  
  ##############################################################
  # CONDUCTING THE SMC
  ##############################################################
  
  # Initialise other required quantities 
  data <- matrix(0, I, 2) # Set up data
  log_Z = matrix(0, 1, K) # initialise log estimate of evidence
  loglik = matrix(0, N, K) # initialise vector of log likelihood
  logpri = matrix(0, N, K) # initialise vector of log prior
  px = matrix(0, N, K) # initialise vector of the log posterior
  w = matrix(0, N, K) # initialise vector of unnormalised weights of particles
  ESS = matrix(0, 1, K) # initialise vector of effective sample size of each model
  
  # Draw theta from prior distribution
  # NOTE: We use local=TRUE so it runs inside this function environment
  source('prior_sampling.R', local = TRUE)
  
  W <- rep(1/N, N * K) %>% matrix(nrow = N)
  
  all_cov_matrices <- list()
  for(M in 1:K){
    all_cov_matrices[[M]] = cov(theta[,,M])
  }
  
  ## RUN SMC ALGORITHM LOOP
  for (i in 1:I){
    
    if(N > 100) {
      cat(paste("    **** Iteration number", i, "**** "), sep ="\n")
    }
    
    if (R %in% c(0, 1, 2, 3, 5)){
      if  (R == 0){
        # Select design points randomly
        data[i,1]= sample(Nmin:Nmax, 1, replace = T)
      }
      else if (R == 1){
        source('parameter_estimation_utility.R', local = TRUE) 
       # source('utility_plot.R', local = TRUE) # JD commenting these out for computation purposes
      }
      else if (R == 2){
        source('model_discrimination_utility.R', local = TRUE) 
        # source('utility_plot.R', local = TRUE)  # JD commenting these out for computation purposes
      }
      else if (R == 3){
        source('total_entropy_utility.R', local = TRUE) 
       # source('utility_plot.R', local = TRUE)  # JD commenting these out for computation purposes
      }
      else {
        data[i,1] <- dataset[i,1] 
      }
      
      # Generate observation from the design point
      data[i,2] <- generate_data(data[i,1], parameter_set, observation_time = time, M_true)[[1]]
    }
    else if(R == 4){
      data[i,] <- dataset[i,] 
    }
    
    data_subset <- data[1:i,, drop = FALSE] 
    
    for (M in 1:K){
      #  Re-weight
      w[,M] = W[,M] * exp(loglikelihood_Hollings(exp(theta[,,M]), data[i,,drop = FALSE], observation_time = time, models[M]))
      log_Z[M] = log_Z[M] + log(sum(w[,M]))
      
      # Normalise weights
      W[,M] = w[,M]/sum(w[,M])
      
      # Compute ESS at time t
      ESS[M] = 1/ sum(W[,M]^2)
      
      if (ESS[M] < E){
        source('resample_then_move.R', local = TRUE)
      }
    }
  }
  
  ##############################################################
  # FINAL RESAMPLING AND RESULTS
  ##############################################################
  
  ## Conduct a final resampling and move step 
  for (M in 1:K){
    if (ESS[M] != N){
      source('resample_then_move.R', local = TRUE)
    }
    
    # Calculate log Bayesian D-posterior precision 
    covariance = cov(exp(theta[,,M]))
    if (models[M] %in% 3:4){covariance = covariance[1:2, 1:2]}
    log_D_post_prec = -log(det(covariance));
    
    # Plot marginal posterior distributions
    cat(paste("Plotting results for Model", models[M]), sep="\n")
    source('SMC_plot.R', local = TRUE)
  }
  
  # Calculate Posterior Model Probabilities
  posterior_model_prob = exp(log_Z - logsumexp(log_Z,0))
  
  # Return a list of the important results to use later if needed
  return(list(
    final_probabilities = posterior_model_prob,
    data_collected = data,
    final_evidence = log_Z,
    final_ESS = ESS
  ))
}



```



```{r run_experiments, echo=TRUE, results='hide', warning=FALSE, message=FALSE}
# --- ORIGINAL VARIABLE COUNT - SENSITIVITY TO PARTICLE COUNT (N) ---
# Showing graphs from original experiment
# We keep R=0 (Random) constant to isolate the effect of N.
set.seed(400)
cat("Running Original Particle Simulation (N=500)...\n")
# CHANGE OF VARIABLE 1: N = 500
results_N_original <- run_smc_simulation(input_N = 500, input_R = 0, input_seed = 400)
```

```{r run_experiments, echo=TRUE, results='hide', warning=FALSE, message=FALSE}
# --- EXPERIMENT 1: Super low N ----
# Hypothesis: Low N will result in unstable probabilities (High Monte Carlo Error).
# We keep R=0 (Random) constant to isolate the effect of N.
set.seed(400)
cat("Running Low Particle Simulation (N=50)...\n")
#  N = 50
results_N_lowest <- run_smc_simulation(input_N = 30, input_R = 0, input_seed = 400)

```

```{r run_experiments, echo=TRUE, results='hide', warning=FALSE, message=FALSE}
# --- EXPERIMENT 1: SENSITIVITY TO PARTICLE COUNT (N) ---
# Hypothesis: Low N will result in unstable probabilities (High Monte Carlo Error).
# We keep R=0 (Random) constant to isolate the effect of N.
set.seed(400)
cat("Running Medium Particle Simulation (N=100)...\n")
# CHANGE OF VARIABLE 1: N = 100
results_N_medium <- run_smc_simulation(input_N = 100, input_R = 0, input_seed = 400)

```
```{r run_experiments, echo=TRUE, results='hide', warning=FALSE, message=FALSE}
# --- EXPERIMENT 1: SENSITIVITY TO PARTICLE COUNT (N) ---
# Hypothesis: Low N will result in unstable probabilities (High Monte Carlo Error).
# We keep R=0 (Random) constant to isolate the effect of N.
set.seed(400)
cat("Running High Particle Simulation (N=1000)...\n")
# CHANGE OF VARIABLE 1: N = 1000
results_N_high <- run_smc_simulation(input_N = 1000, input_R = 0, input_seed = 400)

```




```{r}
#JD: checking effect of Particle Count (N), which was originally N = 500
# This mimics the "Initialisation" phase of the SMC

set.seed(400)

# True parameter we are trying to estimate
true_mean <- 0.5 

# Compare two particle sizes
N_low <- 50    # Your Modification A
N_high <- 5000 # Your Modification B

# Generate particles (Drawing theta from prior)
particles_low <- rnorm(N_low, mean = true_mean, sd = 1)
particles_high <- rnorm(N_high, mean = true_mean, sd = 1)

# Calculate estimates
est_low <- mean(particles_low)
est_high <- mean(particles_high)

# Calculate Standard Error (Monte Carlo Error)
se_low <- sd(particles_low) / sqrt(N_low)
se_high <- sd(particles_high) / sqrt(N_high)

# Output results for your report
cat(paste("True Value: ", true_mean, "\n"))
cat(paste("N=50 Estimate: ", round(est_low, 4), " (Error: ", round(se_low, 4), ")\n"))
cat(paste("N=5000 Estimate: ", round(est_high, 4), " (Error: ", round(se_high, 4), ")\n"))

# Visual check
par(mfrow=c(1,2))
hist(particles_low, main="Low N (Jumpy)", col="red")
abline(v=true_mean, lwd=3)
hist(particles_high, main="High N (Smooth)", col="blue")
abline(v=true_mean, lwd=3)




```


```{r}
# VISUALIZATION: The Statistical Challenge
# Comparing Holling Type II vs Type III Functional Responses with Noise

set.seed(400) # Fix seed so points stay in the same place

# 1. SETUP PARAMETERS
N_prey <- seq(0, 100, by = 1)
a <- 0.5      # Attack rate
Th <- 0.7     # Handling time
T_time <- 24  # Time in hours (Standard daily experiment)

# 2. CALCULATE CURVES (Scaled by Time)
# Type II: (a * N * T) / (1 + a * Th * N)
Type2 <- (a * N_prey * T_time) / (1 + a * Th * N_prey)

# Type III: (a * N^2 * T) / (1 + a * Th * N^2)
Type3 <- (a * N_prey^2 * T_time) / (1 + a * Th * N_prey^2)

# 3. PLOT THE CURVES
# Set ylim to make room for text labels
plot(N_prey, Type2, type = "l", col = "blue", lwd = 3, 
     ylim = c(0, 35),
     ylab = "Prey Eaten (Count)", xlab = "Prey Density (N)",
     main = "The Challenge: Distinguishing Models with Noise")

lines(N_prey, Type3, col = "red", lwd = 3, lty = 2)

legend("bottomright", legend = c("Type II (Glutton)", "Type III (Learner)"),
       col = c("blue", "red"), lty = c(1, 2), lwd = 3)

# 4. SIMULATE "NOISY" DATA (The Challenge)

# Scenario A: Bad Design (High Density)
# Where the lines overlap, data is useless.
bad_N <- 80
# Calculate the "True" Type 2 value and add random noise (sd=2)
bad_point <- ((a * bad_N * T_time) / (1 + a * Th * bad_N)) + .8

points(bad_N, bad_point, pch=19, col="black", cex=1.5)
text(bad_N, bad_point - 5, "Type II or III?\nMuch harder to tell with real, noisy data", pos=2, col="black")

# Scenario B: Good Design (Low Density)
# Where the lines diverge, data is valuable.
good_N <- 8
# Calculate the "True" Type 2 value and add random noise
good_point <- ((a * good_N * T_time) / (1 + a * Th * good_N)) + .35

points(good_N, good_point, pch=19, col="green4", cex=1.5)
# Draw an arrow or line to show the gap
arrows(good_N, good_point, good_N, 5, length=0.1, col="green4")
text(good_N+2, 5, "We need data\nHERE", pos=4, col="green4", font=2)
```

```

